{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760b22b9",
   "metadata": {},
   "source": [
    "# Note Point\n",
    "#### Aim this file 1-  hmne ye file es liye bnae h because hme live video throw detect krna the ke person ne mask phna h ke nhi To usek liye hme phle full image me se face ke crop krna the because hmara model full image(full body image) me se jab face mask ko detect krta to wo wh glti krta the es liye hmen use full image na dekar only face ke image di or then model se detect krwaya to result bhut he achhe aa rhe the so that hmne ye use kiya h\n",
    "#### 2- ab hm furthor ese web site or app me convert kr denge essayly becuase hme bs ab code copy paste krna h yha se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model.h5',compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83f6b8c",
   "metadata": {},
   "source": [
    "## This concept apply jb hm video ke throw live btaege ke human ne mask phna h ke nhi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b434c",
   "metadata": {},
   "source": [
    "# Plan of Atack\n",
    "### 1- detect the face (bounding box created) video me se\n",
    "### 2- save the frame in your image\n",
    "### 3- frame ke uper model ko apply ke do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e602584e",
   "metadata": {},
   "source": [
    "# 1 Step\n",
    "##### detect the face (bounding box created) video me se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "harr = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # yha hmarae img me image store hoti h per seond ke minuts se\n",
    "    flag  , img = capture.read()\n",
    "    \n",
    "    if flag: # Ye Flag btata h ke image capture ke ja rhi h \n",
    "        # Jb ye True hoga tabhi hm image me se face ke coodenates nikal paenge\n",
    "        \n",
    "        faces = harr.detectMultiScale(img)\n",
    "        for x , y , w , h in faces:\n",
    "            cv2.rectangle(img , (x , y) , (x+w , y+h) ,(255 ,0 ,255), 4)\n",
    "            # \n",
    "            face = img[y:y+h, x:x+w]\n",
    "            \n",
    "            \n",
    "\n",
    "           \n",
    "            \n",
    "\n",
    "\n",
    "        cv2.imshow('result', img)\n",
    "        if cv2.waitKey(2) == 27:\n",
    "            break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd749ba",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "while True:\n",
    "    \n",
    "    flag  , img = capture.read()\n",
    "    if flag:     \n",
    "        faces = harr.detectMultiScale(img)\n",
    "        for x , y , w , h in faces:\n",
    "            cv2.rectangle(img , (x , y) , (x+w , y+h) ,(255 ,0 ,255), 4)\n",
    "            \n",
    "            \n",
    "# <<<<<<<<<< Step 2 Workin <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "            face = img[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, (224,224))\n",
    "            face = face.reshape(1,224,224,3)\n",
    "          \n",
    "            \n",
    "\n",
    "        cv2.imshow('result', img)\n",
    "        if cv2.waitKey(2) == 27:\n",
    "            break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728509a4",
   "metadata": {},
   "source": [
    "# step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a40948",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {0:\"mask_weared_incorrect\" , 1:\"with_mask\", 2:\"without_mask\"}\n",
    "y_pred = model.predict(face)\n",
    "            y_pred = y_pred.argmax(axis=-1)[0]\n",
    "            \n",
    "            n = names[int(y_pred)]\n",
    "            cv2.putText(img, n, (x,y) , font ,1,(244,250,250),2)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc65b3",
   "metadata": {},
   "source": [
    "# ALL in One\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bddeb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {0:\"mask_weared_incorrect\" , 1:\"with_mask\", 2:\"without_mask\"}\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # yha hmarae img me image store hoti h per seond ke minuts se\n",
    "    flag  , img = capture.read()\n",
    "    \n",
    "    if flag: # Ye Flag btata h ke image capture ke ja rhi h \n",
    "        # Jb ye True hoga tabhi hm image me se face ke coodenates nikal paenge\n",
    "        \n",
    "        faces = harr.detectMultiScale(img)\n",
    "        for x , y , w , h in faces:\n",
    "            cv2.rectangle(img , (x , y) , (x+w , y+h) ,(255 ,0 ,255), 4)\n",
    "            # \n",
    "            face = img[y:y+h, x:x+w]\n",
    "            \n",
    "#             print(plt.imshow(face))\n",
    " \n",
    "            face = cv2.resize(face, (224,224))\n",
    "            face = face.reshape(1,224,224,3)\n",
    "            y_pred = model.predict(face)\n",
    "            y_pred = y_pred.argmax(axis=-1)[0]\n",
    "            \n",
    "            n = names[int(y_pred)]\n",
    "            cv2.putText(img, n, (x,y) , font ,1,(244,250,250),2)\n",
    "            \n",
    "#>>>>>>     print(n)\n",
    "\n",
    "        cv2.imshow('result', img)\n",
    "        if cv2.waitKey(2) == 27:\n",
    "            break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ddd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "Registration Link : https://www.hackerearth.com/challenges/new/competitive/amazon-ml-challenge-2023/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1 ,32,5,6,7,8,9,0,9,3]\n",
    "\n",
    "for i in range(40):\n",
    "    if i[l] <= len(l):\n",
    "        continue\n",
    "    elif i[l] is not None:\n",
    "        print(i[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dsf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c086f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
